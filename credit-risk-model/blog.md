# Description

This folder contains code that is working and was used as a final pipeline to build a risk scoring model. There are various steps followed in the pipeline which includes

- [Data ingestion](src/ingest.py): In this stage,  the data is gathered from sources.
- [Separation](src/test_train_split.py): Separate the train from the test and validation data
- [Preprocessing](src/preprocess.py): In this step, we preprocess the data including transforming every feature to ordinal data using WOE. The package of choice is OptBinning. OptBinning is a powerful Python library that provides advanced binning techniques for data preprocessing and feature engineering. One of its key components is the **BinningProcess** module, which offers a wide range of binning algorithms, including optimal binning methods such as Recursive Partitioning and Dynamic Programming. With OptBinning's BinningProcess, you can efficiently transform continuous variables into categorical bins, improving the interpretability and predictive power of your models. You can handle data preprocessing challenges, such as reducing noise, handling outliers, and capturing non-linear relationships, ultimately enhancing the accuracy and interpretability of your models.
- [Clustering](src/clustering.py): This is a feature reduction stage. The features are clustered together based on their correlation. The output is a list of automatically selected features. The feature with the highes informational value and the one at the center of the cluster are selected. The package of choice is **Varclushi**. Varclushi is a Python package designed for feature selection and dimensionality reduction. It implements a variant of the clustering-based feature selection method called "variance component analysis." With Varclushi, you can identify and eliminate redundant or irrelevant features from your dataset, leading to more efficient and interpretable models. By leveraging clustering and statistical techniques, Varclushi helps uncover the most informative features and improve overall model performance.
- [Feature selection](src/featurization.py): In the feature selection stage, a further smaller number of feature are further selected to provide a parsimonous model. The module of choice is Scikit-learn **RFECV (Recursive Feature Elimination with Cross-Validation)**. RFECV is a feature selection technique in sklearn that recursively eliminates less important features by repeatedly training models and selecting the optimal subset of features based on cross-validation performance. RFECV helps improve model interpretability, reduce overfitting, and enhance prediction accuracy by automatically selecting the most relevant features for the task at hand.
- [Model](src/scorecard.py): The model stage involves building a scorecard with the final features. The scorecard is a classification model that is converted into a score so that it outputs a range of scores. The algorithms and packages will be scikit-learn **LogisticRegression** in combination with OptBinning Scorecard. LogisticRegression is a classification algorithm in sklearn that is widely used for binary and multiclass classification problems. It fits a logistic regression model to the training data and predicts the probability of class membership for new observations. LogisticRegression is known for its simplicity, interpretability, and effectiveness in various domains. It is particularly useful when dealing with binary classification tasks, where the goal is to predict the probability of an instance belonging to a particular class. The **Scorecard** module in OptBinning allows you to develop scorecards by combining binning and logistic regression, facilitating credit risk modeling and scoring applications.

To run each of the stage, activate the environment in Chapter 5, and run

```py
python src/stage-code.py
```

Sure! Here are the descriptions for the Python libraries and packages you mentioned:

1. **Optbinning**: Optbinning is a powerful Python library for optimal binning of continuous and categorical variables. It offers a comprehensive set of algorithms to discretize data into bins, allowing for improved data representation and better modeling performance. With Optbinning, you can handle data preprocessing challenges, such as reducing noise, handling outliers, and capturing non-linear relationships, ultimately enhancing the accuracy and interpretability of your models.

2. **Varclushi**: Varclushi is a Python package designed for feature selection and dimensionality reduction. It implements a variant of the clustering-based feature selection method called "variance component analysis." With Varclushi, you can identify and eliminate redundant or irrelevant features from your dataset, leading to more efficient and interpretable models. By leveraging clustering and statistical techniques, Varclushi helps uncover the most informative features and improve overall model performance.

3. **Scikit-learn (sklearn)**: Sklearn is a widely-used Python library for machine learning and data analysis. It provides a vast array of tools and algorithms for various tasks, including classification, regression, clustering, and dimensionality reduction. Two specific components of sklearn are RFECV and LogisticRegression:

   - **RFECV (Recursive Feature Elimination with Cross-Validation)**: RFECV is a feature selection technique in sklearn that recursively eliminates less important features by repeatedly training models and selecting the optimal subset of features based on cross-validation performance. RFECV helps improve model interpretability, reduce overfitting, and enhance prediction accuracy by automatically selecting the most relevant features for the task at hand.

   - **LogisticRegression**: LogisticRegression is a classification algorithm in sklearn that is widely used for binary and multiclass classification problems. It fits a logistic regression model to the training data and predicts the probability of class membership for new observations. LogisticRegression is known for its simplicity, interpretability, and effectiveness in various domains. It is particularly useful when dealing with binary classification tasks, where the goal is to predict the probability of an instance belonging to a particular class.

These libraries and packages provide valuable functionality and tools to support different stages of the machine learning pipeline, enabling data preprocessing, feature selection, and model training with ease and efficiency.


Pick One

1. **Optbinning** - OptBinning is a powerful Python library that provides advanced binning techniques for data preprocessing and feature engineering. One of its key components is the **BinningProcess** module, which offers a wide range of binning algorithms, including optimal binning methods such as Recursive Partitioning and Dynamic Programming. With OptBinning's BinningProcess, you can efficiently transform continuous variables into categorical bins, improving the interpretability and predictive power of your models. Additionally, the **Scorecard** module in OptBinning allows you to develop scorecards by combining binning and logistic regression, facilitating credit risk modeling and scoring applications.

2. **Varclushi** - Varclushi is a Python package designed for variable selection and clustering tasks. It implements a variety of advanced techniques, including Variable Clustering, that help identify groups of variables with similar characteristics or patterns. By leveraging dimensionality reduction algorithms and clustering algorithms, Varclushi aids in reducing the complexity of high-dimensional datasets, extracting key information, and enhancing interpretability. This package is particularly useful in scenarios where feature selection is crucial for improving model performance and reducing overfitting.

3. **Scikit-learn (sklearn)** - Scikit-learn is a widely used machine learning library in Python that offers a comprehensive set of tools for data analysis and model building. Within Scikit-learn, two key components stand out: **RFECV (Recursive Feature Elimination with Cross-Validation)** and Logistic Regression. RFECV is a feature selection technique that recursively eliminates less informative features based on their importance, as measured by cross-validated performance. This automated process helps identify the most relevant features, improving model efficiency and interpretability. **Logistic Regression**, on the other hand, is a popular classification algorithm that estimates the probability of a binary outcome. With Scikit-learn's Logistic Regression implementation, you can easily fit logistic regression models, assess model performance, and make predictions based on the learned coefficients.