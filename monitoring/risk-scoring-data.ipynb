{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evidently Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "from evidently import ColumnMapping\n",
    "from evidently.report import Report\n",
    "from evidently.metrics import ColumnDriftMetric, DatasetDriftMetric, DatasetMissingValuesMetric\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from optbinning import Scorecard, BinningProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = [\n",
    "            \"AverageMInFile\",\n",
    "            \"MSinceMostRecentInqexcl7days\",\n",
    "            \"PercentTradesNeverDelq\",\n",
    "            \"ExternalRiskEstimate\",\n",
    "            \"NetFractionRevolvingBurden\",\n",
    "            \"NumSatisfactoryTrades\",\n",
    "            \"PercentInstallTrades\"\n",
    "      ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_mapping = ColumnMapping(\n",
    "    target=\"RiskPerformance\",\n",
    "    prediction='prediction',\n",
    "    numerical_features=num_features,\n",
    "    # categorical_features=cat_features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = Report(metrics=[\n",
    "    ColumnDriftMetric(column_name='prediction'),\n",
    "    DatasetDriftMetric(),\n",
    "    DatasetMissingValuesMetric()\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = \"RiskPerformance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Scorecard.load(\"/home/fini/Learning/CreditRisk/crm-simple-scorecard/mlops-model/data/artifacts/rfecv/scorecard-model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_data():\n",
    "    base_path = \"/home/fini/Learning/CreditRisk/crm-simple-scorecard/mlops-model/data\"\n",
    "    x_train = pd.read_parquet(f\"{base_path}/X_train.parquet\")\n",
    "    y_train = pd.read_parquet(f\"{base_path}/y_train.parquet\")\n",
    "    x_val = pd.read_parquet(f\"{base_path}/X_val.parquet\")\n",
    "    y_val = pd.read_parquet(f\"{base_path}/y_val.parquet\")\n",
    "    target = \"RiskPerformance\"\n",
    "    train = x_train.assign(RiskPerformance=y_train.values)\n",
    "    val = x_val.assign(RiskPerformance=y_val.values)\n",
    "\n",
    "    return train[num_features], val[num_features]\n",
    "\n",
    "    \n",
    "train_data, val_data = get_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Drift in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_drift(data):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    p = 0.1 #percentage missing data required\n",
    "\n",
    "    df = pd.DataFrame(np.random.randint(0,100,size=(10,10)))\n",
    "\n",
    "    mask = np.random.choice([True, False], size=data.shape, p=[p,1-p])\n",
    "    return data.mask(mask)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = add_drift(train_data), add_drift(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Gaussian noise to some of the data.\n",
    "import numpy as np \n",
    "def add_gaussian_noise(df):\n",
    "\n",
    "    df = df.copy()\n",
    "    std = df.describe().to_dict(orient=\"records\")[2]\n",
    "    for column in df.columns:\n",
    "        mu, sigma = 0, std[column]\n",
    "        # creating a noise with the same dimension as the dataset (2,2) \n",
    "        noise = np.random.normal(mu, sigma, df[column].shape) \n",
    "        df[column] = df[column] + noise\n",
    "\n",
    "    return df\n",
    "\n",
    "def noisy_data(df):\n",
    "    df = df.copy()\n",
    "    stats = df.describe().to_dict(orient=\"records\")\n",
    "    std = stats[2]\n",
    "    mean = stats[1]\n",
    "    for column in df.columns:\n",
    "        mu, sigma = mean[column], std[column]\n",
    "        # creating a noise with the same dimension as the dataset (2,2) \n",
    "        noise = np.random.normal(mu, sigma, df[column].shape) \n",
    "        df[column] = noise\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drift_data = add_gaussian_noise(val_data.sample(1000))\n",
    "noise_data = noisy_data(val_data.sample(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_noisy_data = pd.concat([drift_data, noise_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_noisy_data[\"operation_date\"] = [date(2023, 10, day) for day in np.random.randint(1, 13, size=raw_noisy_data.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_noisy_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date(2020, 10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_date(size, year = 2023):\n",
    "    days = np.random.randint(1, 29,size=(size))\n",
    "    months = np.random.randint(1, 13,size=(size))\n",
    "    year = 2023\n",
    "    date_data = [date(year, month, day) for month, day in zip(months, days) ]\n",
    "\n",
    "    return date_data\n",
    "\n",
    "date_col = add_date(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = val_data.assign(operation_date=add_date(val_data.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_raw_data = pd.concat([raw_data, raw_noisy_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = model.predict(val_data[num_features])\n",
    "val_data['prediction'] = val_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data.describe().to_dict(orient=\"records\")[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = model.predict(train_data[num_features])\n",
    "train_data['prediction'] = train_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_parquet(\"data/train.parquet\")\n",
    "val_data.to_parquet(\"data/val.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_parquet(\"data/reference.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_raw_data.to_parquet(\"data/raw.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = pd.read_parquet(\"data/train.parquet\")\n",
    "# val_data = pd.read_parquet(\"data/val.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = model.predict(train_data[num_features])\n",
    "train_data['prediction'] = train_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = model.predict(val_data[num_features])\n",
    "val_data['prediction'] = val_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.run(reference_data=train_data, current_data=val_data, column_mapping=column_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.show(mode='inline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = report.as_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction drift\n",
    "result['metrics'][0]['result']['drift_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of drifted columns\n",
    "result['metrics'][1]['result']['number_of_drifted_columns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#share of missing values\n",
    "result['metrics'][2]['result']['current']['share_of_missing_values']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.timedelta(days=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "05-monitoring-NIVV9OLH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
